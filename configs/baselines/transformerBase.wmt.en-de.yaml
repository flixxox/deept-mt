# Pipeline Arguments
qsub_mem_train:   '32G'
qsub_time_train:  '168:00:00'
qsub_mem_search:  '8G'
qsub_time_search: '48:00:00'

data_train_root:  '/home/fschmidt/data/wmt14/en-de/webdataset'
data_train_mask:  'train.tar'

data_dev_root:    '/home/fschmidt/data/wmt14/en-de/webdataset'
data_dev_mask:    'dev.tar'

data_test_root:    '/home/fschmidt/data/wmt14/en-de/webdataset'
data_test_mask:    'test.tar'
corpus_size_test:  3003

test_src_comet:    '/home/fschmidt/data/wmt14/en-de/comet/test.en.detok' # DeepT workflow
test_ref:          '/home/fschmidt/data/wmt14/en-de/ref/test.de.detok' # DeepT workflow

vocab_src:        '/home/fschmidt/data/wmt14/en-de/vocabs/source.vocab.pkl'
vocab_tgt:        '/home/fschmidt/data/wmt14/en-de/vocabs/target.vocab.pkl'

data_decoding:      'text'
data_preprocess:    'mt_preprocess'
data_collate:       'mt_collate'
data_len_fn:        'mt_tgt_len_fn'
postprocessing_fn:  'mt_postprocess'

search_test_set:          True
batch_size:               1700  # [target tokens without padding]
batch_size_search:        100   # [target tokens without padding]
update_freq:              16
min_sample_size:          3
max_sample_size:          128

dataloader_workers:                   4
buffer_size_bucketing:                50000
buffer_size_batch_shuffling:          1000
buffer_size_shuffle_before_batching:  150000

number_of_gpus:   1
seed:             80420
deterministic:    False

mixed_precision_training: True

checkpoints:                  True
checkpoint_unit:              'Step' # ['Step', 'Epoch']
checkpoint_strategy:          'All' # ['All', 'Best']
checkpoint_period:            1000
checkpoint_start_after:       10000
units_to_train:               150000

average_last_after_best_checkpoints:  True
average_last_checkpoints:             True
checkpoints_to_average:               7
best_checkpoint_indicator:            'ppl'

model:        'Transformer'
model_input:  ['src', 'tgt']
encL:         6
decL:         6
model_dim:    512
ff_dim:       2048
dropout:      0.1
nHeads:       8
tiew:         True

gating:                   False
use_sinusodial_pos_embed: True

initializer:              'GlorotUniform'
variance_scaling_scale:   0.78

criterion:            'LabelSmoothingCrossEntropy'
scores:               ['CrossEntropy']
label_smoothing:      0.1

optimizer:        'Adam'
lr_scheduler:     'Warmup'
warmup_steps:     4000
warmup_lr_scale:  1.0

search_algorithm:   'MTBeamSearch'
beam_search_input:  ['src']
beam_size:          12
length_norm:        True
length_penalty:     0.0
stepwise:           True

search_print_per_step_keys: ['src', 'result', out]