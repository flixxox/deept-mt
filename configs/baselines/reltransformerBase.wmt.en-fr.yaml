# Pipeline Arguments
qsub_mem_train:   '96G'
qsub_time_train:  '168:00:00'
qsub_mem_search:  '16G'
qsub_time_search: '24:00:00'

train_src:  "/home/fschmidt/data/wmt14/en-fr/train.en"
train_tgt:  "/home/fschmidt/data/wmt14/en-fr/train.fr"

dev_src:    "/home/fschmidt/data/wmt14/en-fr/valid.en"
dev_tgt:    "/home/fschmidt/data/wmt14/en-fr/valid.fr"
dev_ref:    "/home/fschmidt/data/wmt14/en-fr/ref/valid.fr"

test_src:   "/home/fschmidt/data/wmt14/en-fr/test.en"
test_tgt:   "/home/fschmidt/data/wmt14/en-fr/test.fr"
test_ref:   "/home/fschmidt/data/wmt14/en-fr/ref/test.fr"

vocab_src:  "/home/fschmidt/data/wmt14/en-fr/source.vocab.pkl"
vocab_tgt:  "/home/fschmidt/data/wmt14/en-fr/target.vocab.pkl"

number_of_gpus:   2
seed:             80420
deterministic:    True

dataset:                "TranslationDataset"
load_datset_in_memory:  True
search_test_set:        True
threaded_data_loading:  False
batch_size:             1700  # [target tokens without padding] [1024,2048]
batch_size_search:      512   # [target tokens without padding]
max_sentence_length:    128

checkpoints:                  True
checkpoint_unit:              'Step' # ['Step', 'Epoch']
checkpoint_strategy:          'All' # ['All', 'Best']
checkpoint_period:            1000
checkpoint_start_after:       10000

units_to_train: 150000

average_last_after_best_checkpoints:  True
average_last_checkpoints:             True
checkpoints_to_average:               7

model:      'RelTransformer'
encL:       6
decL:       6
model_dim:  512
ff_dim:     2048
dropout:    0.1
nHeads:     8
tiew:       True
K:          16

gating:                   False
only_rel_attention:       False

initializer:              'GlorotUniform'
variance_scaling_scale:   0.78

score:            'LabelSmoothingCrossEntropy'
label_smoothing:  0.1

optimizer:    'WarmupAdam'
warmup:       4000
lr_scale:     1.0
update_freq:  16

search_algorithm:   'Beam'
beam_size:          12
length_norm:        True
stepwise:           True